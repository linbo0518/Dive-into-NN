# Dive into NN: Theory, Architecture and Initialization

Oral for AI-ML-Club(`AMC` for short), for more detail about our club, check out our [GitHub](https://github.com/BUPT/ai-ml.club) and [Website](https://ai-ml.club/)

- [Dive into NN: Theory, Architecture and Initialization](#Dive-into-NN-Theory-Architecture-and-Initialization)
  - [Material](#Material)
    - [Paper](#Paper)
    - [Link](#Link)
  - [Slide](#Slide)
  - [Thinking](#Thinking)
  - [Todo](#Todo)

## Material

### Paper

- [Rethinking The Value of Network Pruning](https://arxiv.org/abs/1810.05270)
- [The Lottery Ticket Hypothesis- Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635)
- [The Benefits of Over-parameterization at Initialization in Deep ReLU Networks](https://arxiv.org/abs/1901.03611)
- [Stabilizing the Lottery Ticket Hypothesis](https://arxiv.org/abs/1903.01611)
- [Luck Matters: Understanding Training Dynamics of Deep ReLU Networks](https://arxiv.org/abs/1905.13405)
- [How to Initialize your Network](https://arxiv.org/abs/1906.02341)

### Link

- [如何评价ICLR 2019最佳论文《The Lottery Ticket Hypothesis》？](https://www.zhihu.com/question/323214798)
- [求道之人，不问寒暑（三）](https://zhuanlan.zhihu.com/p/67782029)

## Slide

[Google Slide](https://docs.google.com/presentation/d/1cQqC3SRYlZypvQFtG7pvkBzYK1hMgu8HjwO5qvlX48Q/edit?usp=sharing)(under construction...)

## Thinking

> under construction

## Todo

- [ ] add more link
- [ ] finish slide
- [ ] finish thinking
